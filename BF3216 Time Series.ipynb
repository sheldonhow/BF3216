{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a207d2",
   "metadata": {},
   "source": [
    "# Modelling with Time Series\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9802f9",
   "metadata": {},
   "source": [
    "##### The cell below extracts the history of the default rates per credit rating and is input into a Time Series model\n",
    "##### This will allow the model to forecast the future expected default rates, under Mild, Base and Severe scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "616c81ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR(1) parameters per rating:\n",
      "rating    alpha       phi    sigma  last_dr      q95  n_obs\n",
      "   Aaa 0.000000  0.000000 0.000000   0.0000 0.000000    104\n",
      "    Aa 0.000586 -0.005968 0.001733   0.0000 0.004850    104\n",
      "     A 0.000508  0.392944 0.002341   0.0015 0.003925    104\n",
      "   Baa 0.001204  0.497571 0.003791   0.0011 0.010740    104\n",
      "    Ba 0.005157  0.480023 0.014090   0.0073 0.037935    104\n",
      "     B 0.016183  0.468694 0.032810   0.0072 0.101830    104\n",
      " Caa-C 0.070930  0.314649 0.104467   0.0916 0.333300    104\n",
      "\n",
      "Year 5 Mild/Base/Severe (by rating):\n",
      "rating  DR_mild  DR_base  DR_severe\n",
      "   Aaa      0.0 0.000000   0.000000\n",
      "    Aa      0.0 0.000582   0.004048\n",
      "     A      0.0 0.000843   0.003925\n",
      "   Baa      0.0 0.002357   0.010740\n",
      "    Ba      0.0 0.009850   0.037935\n",
      "     B      0.0 0.029932   0.101830\n",
      " Caa-C      0.0 0.103457   0.323571\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "wide_csv_path = Path(\"clean_credit_default_rates_wide.csv\")  # adjust if needed\n",
    "\n",
    "\n",
    "wide = pd.read_csv(wide_csv_path)\n",
    "# normalize column names\n",
    "wide.columns = [c.strip() for c in wide.columns]\n",
    "year_col = [c for c in wide.columns if c.lower().startswith(\"year\")][0]\n",
    "wide = wide.set_index(year_col).sort_index()\n",
    "\n",
    "\n",
    "ratings = [c for c in [\"Aaa\",\"Aa\",\"A\",\"Baa\",\"Ba\",\"B\",\"Caa-C\"] if c in wide.columns]\n",
    "\n",
    "# put this helper once, above the loop\n",
    "def horizon_sigma(phi, sigma, h):\n",
    "    # σ_h = σ * sqrt( sum_{j=0}^{h-1} φ^(2j) )\n",
    "    if abs(phi) < 0.999:\n",
    "        return sigma * ((1 - (phi**2)**h) / (1 - phi**2))**0.5\n",
    "    else:\n",
    "        # safe fallback if phi≈1\n",
    "        return sigma * (h**0.5)\n",
    "\n",
    "\n",
    "# Helper: fit AR(1) with sensible fallback\n",
    "def fit_ar1(series: pd.Series):\n",
    "    series = series.dropna()\n",
    "    info = {\"n_obs\": len(series)}\n",
    "    if len(series) < 5:\n",
    "        # Fallback: use mean level, zero persistence, sigma from series\n",
    "        mu = float(series.mean())\n",
    "        sigma = float(series.std(ddof=1)) if len(series) > 1 else 0.0\n",
    "        q95 = float(np.nanpercentile(series.values, 95)) if len(series) > 1 else mu\n",
    "        return dict(alpha=mu*(1-0.0), phi=0.0, sigma=sigma, last_dr=float(series.iloc[-1]), q95=q95, **info)\n",
    "\n",
    "    y = series.iloc[1:].values\n",
    "    x = sm.add_constant(series.iloc[:-1].values)\n",
    "    model = sm.OLS(y, x, missing=\"drop\").fit()\n",
    "    alpha, phi = model.params\n",
    "    sigma = float(model.resid.std(ddof=1))\n",
    "    last_dr = float(series.iloc[-1])\n",
    "    q95 = float(np.nanpercentile(series.values, 95))\n",
    "    # Guardrails\n",
    "    if abs(phi) > 0.98:  # avoid explosive forecasts\n",
    "        mu = float(series.mean())\n",
    "        alpha, phi = mu*(1-0.0), 0.0\n",
    "    return dict(alpha=float(alpha), phi=float(phi), sigma=sigma, last_dr=last_dr, q95=q95, **info)\n",
    "\n",
    "# Fit AR(1) per rating\n",
    "params = []\n",
    "for r in ratings:\n",
    "    p = fit_ar1(wide[r])\n",
    "    p[\"rating\"] = r\n",
    "    params.append(p)\n",
    "ar_params = pd.DataFrame(params)[[\"rating\",\"alpha\",\"phi\",\"sigma\",\"last_dr\",\"q95\",\"n_obs\"]]\n",
    "\n",
    "# Forecast 5 or any year Base/Mild/Severe per rating\n",
    "H = 10\n",
    "rows = []\n",
    "for _, row in ar_params.iterrows():\n",
    "    base = [row[\"last_dr\"]]\n",
    "    for _ in range(H):\n",
    "        nxt = row[\"alpha\"] + row[\"phi\"] * base[-1]\n",
    "        base.append(max(nxt, 0.0))\n",
    "    base = base[1:]\n",
    "\n",
    "    # --- horizon-scaled bands (fan out with h) ---\n",
    "    mild, severe = [], []\n",
    "    for h in range(1, H+1):\n",
    "        sig_h = horizon_sigma(row[\"phi\"], row[\"sigma\"], h)\n",
    "        m = max(base[h-1] - sig_h, 0.0)                 # ~1σ below\n",
    "        s = min(base[h-1] + 2.0*sig_h, row[\"q95\"])      # ~2σ above, capped at q95\n",
    "        mild.append(m)\n",
    "        severe.append(s)\n",
    "\n",
    "    for h in range(1, H+1):\n",
    "        rows.append({\n",
    "            \"rating\": row[\"rating\"],\n",
    "            \"year_ahead\": h,\n",
    "            \"DR_mild\": mild[h-1],\n",
    "            \"DR_base\": base[h-1],\n",
    "            \"DR_severe\": severe[h-1],\n",
    "        })\n",
    "\n",
    "forecast = pd.DataFrame(rows)\n",
    "\n",
    "# Quick views\n",
    "print(\"AR(1) parameters per rating:\")\n",
    "print(ar_params.round(6).to_string(index=False))\n",
    "print(\"\\nYear 5 Mild/Base/Severe (by rating):\")\n",
    "print(forecast[forecast[\"year_ahead\"]==5][[\"rating\",\"DR_mild\",\"DR_base\",\"DR_severe\"]].round(6).to_string(index=False))\n",
    "\n",
    "# Optional: save for reuse\n",
    "ar_params.to_csv(\"ar1_params_by_rating.csv\", index=False)\n",
    "forecast.to_csv(\"ar1_forecasts_5y.csv\", index=False)  #name doesn't matter, data will be updated everytime this is ran\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbafab",
   "metadata": {},
   "source": [
    "##### Below are the dataframe of our porfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f7f4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds1 = pd.DataFrame({\n",
    "\n",
    "    \"id\": [\n",
    "        \"Verizon\",\"Deutsche\",\"Anglian Water (Osprey) Financing Plc\",\"Citigroup Inc.\",\"Intesa Sanpaolo S.p.A.\",\n",
    "        \"Santander UK plc\",\"Standard Chartered PLC\",\"Vontobel Holding AG\",\"CVS Health Corporation\",\n",
    "        \"DENTSPLY SIRONA Inc.\",\"Rogers Memorial Hospital Inc.\",\"Baglan Moor Healthcare Plc\",\n",
    "        \"Ochsner LSU Health System of North Louisiana\",\"AT&T Inc.\",\"Bell Canada, Inc.\",\n",
    "        \"British Telecommunications plc\",\"NBN Co Limited\",\"Energy Transfer LP\",\n",
    "        \"Keenan Fort Detrick Energy, LLC\",\"PacifiCorp\",\"TechnipFMC plc\"\n",
    "    ],\n",
    "\n",
    "    \"rating\": [\n",
    "        \"Baa\",\"A\",\"Baa\",\"Baa\",\"Baa\",\"Baa\",\"Ba\",\"Ba\",\"Ba\",\"Ba\",\n",
    "        \"A\",\"Aa\",\"Baa\",\"Baa\",\"Ba\",\"Baa\",\"Aa\",\"Ba\",\"Aa\",\"Baa\",\"Baa\"\n",
    "    ],\n",
    "    \"security_class\": [\n",
    "        \"Senior Secured\",\"Senior Secured\",\"Senior Secured\",\"Senior Unsecured\",\"Senior Unsecured\",\n",
    "        \"Subordinate\",\"Junior Subordinate\",\"Subordinate\",\"Junior Subordinate\",\"Junior Subordinate\",\n",
    "        \"Senior Secured\",\"Secured\",\"Senior Secured\",\"Senior Unsecured\",\"Junior Subordinate\",\n",
    "        \"Senior Unsecured\",\"Senior Unsecured\",\"Junior Subordinate\",\"Senior Secured\",\"Junior Subordinate\",\n",
    "        \"Senior Unsecured\"\n",
    "    ],\n",
    "    \"weight\": [\n",
    "        0.11,0.11,0.02,0.07,0.02,0.08,0.02,0.08,0.02,0.08,\n",
    "        0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.08,0.02,0.02,0.03\n",
    "    ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc30ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "ETF_COMPOSITION = {\n",
    "    \"IBHI\": {\"Baa\": 0.0007, \"Ba\": 0.4398, \"B\": 0.3917, \"Caa-C\": 0.1570},\n",
    "    \"BNDX\": {\"Aa\": 0.0187, \"A\": 0.0414, \"Baa\": 0.4070, \"Ba\": 0.5292},\n",
    "    \"PGHY\": {\"Aa\": 0.2472, \"A\": 0.2662, \"Baa\": 0.2756, \"Ba\": 0.1843, \"B\": 0.0268}\n",
    "}\n",
    "\n",
    "\n",
    "ETF_WEIGHTS = {\"IBHI\": 0.02, \"BNDX\": 0.02, \"PGHY\": 0.06}\n",
    "\n",
    "\n",
    "security_split = {\"Senior Unsecured\": 0.5, \"Subordinate\": 0.5}\n",
    "\n",
    "# \n",
    "rows = []\n",
    "for etf, comp in ETF_COMPOSITION.items():\n",
    "    etf_weight = ETF_WEIGHTS[etf]\n",
    "    for rating, pct in comp.items():\n",
    "        for sec, sec_share in security_split.items():\n",
    "            rows.append({\n",
    "                \"id\": f\"{etf}-{rating}-{sec}\",\n",
    "                \"instrument\": etf,\n",
    "                \"rating\": rating,\n",
    "                \"security_class\": sec,\n",
    "                \"weight\": etf_weight * pct * sec_share\n",
    "            })\n",
    "\n",
    "etf_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4ec30",
   "metadata": {},
   "source": [
    "#### Sanity checks below, running solely on the portfolio without the ETFs, just for model testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd54c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Portfolio 5-year EDL (Base): 0.338%\n",
      "                                          id rating  weight  LGD       DR      EDL\n",
      "                                     Verizon    Baa    0.11 0.50 0.002357 0.001179\n",
      "                                    Deutsche      A    0.11 0.50 0.000843 0.000421\n",
      "        Anglian Water (Osprey) Financing Plc    Baa    0.02 0.50 0.002357 0.001179\n",
      "                              Citigroup Inc.    Baa    0.07 0.65 0.002357 0.001532\n",
      "                      Intesa Sanpaolo S.p.A.    Baa    0.02 0.65 0.002357 0.001532\n",
      "                            Santander UK plc    Baa    0.08 0.80 0.002357 0.001886\n",
      "                      Standard Chartered PLC     Ba    0.02 0.95 0.009850 0.009358\n",
      "                         Vontobel Holding AG     Ba    0.08 0.80 0.009850 0.007880\n",
      "                      CVS Health Corporation     Ba    0.02 0.95 0.009850 0.009358\n",
      "                        DENTSPLY SIRONA Inc.     Ba    0.08 0.95 0.009850 0.009358\n",
      "               Rogers Memorial Hospital Inc.      A    0.02 0.50 0.000843 0.000421\n",
      "                  Baglan Moor Healthcare Plc     Aa    0.02 0.50 0.000582 0.000291\n",
      "Ochsner LSU Health System of North Louisiana    Baa    0.02 0.50 0.002357 0.001179\n",
      "                                   AT&T Inc.    Baa    0.02 0.65 0.002357 0.001532\n",
      "                           Bell Canada, Inc.     Ba    0.02 0.95 0.009850 0.009358\n",
      "              British Telecommunications plc    Baa    0.02 0.65 0.002357 0.001532\n",
      "                              NBN Co Limited     Aa    0.02 0.65 0.000582 0.000378\n",
      "                          Energy Transfer LP     Ba    0.08 0.95 0.009850 0.009358\n",
      "             Keenan Fort Detrick Energy, LLC     Aa    0.02 0.50 0.000582 0.000291\n",
      "                                  PacifiCorp    Baa    0.02 0.95 0.002357 0.002239\n",
      "                              TechnipFMC plc    Baa    0.03 0.65 0.002357 0.001532\n",
      "\n",
      "Portfolio 5-year EDL (Severe): 1.356%\n",
      "                                          id rating  weight  LGD       DR      EDL\n",
      "                                     Verizon    Baa    0.11 0.50 0.010740 0.005370\n",
      "                                    Deutsche      A    0.11 0.50 0.003925 0.001962\n",
      "        Anglian Water (Osprey) Financing Plc    Baa    0.02 0.50 0.010740 0.005370\n",
      "                              Citigroup Inc.    Baa    0.07 0.65 0.010740 0.006981\n",
      "                      Intesa Sanpaolo S.p.A.    Baa    0.02 0.65 0.010740 0.006981\n",
      "                            Santander UK plc    Baa    0.08 0.80 0.010740 0.008592\n",
      "                      Standard Chartered PLC     Ba    0.02 0.95 0.037935 0.036038\n",
      "                         Vontobel Holding AG     Ba    0.08 0.80 0.037935 0.030348\n",
      "                      CVS Health Corporation     Ba    0.02 0.95 0.037935 0.036038\n",
      "                        DENTSPLY SIRONA Inc.     Ba    0.08 0.95 0.037935 0.036038\n",
      "               Rogers Memorial Hospital Inc.      A    0.02 0.50 0.003925 0.001962\n",
      "                  Baglan Moor Healthcare Plc     Aa    0.02 0.50 0.004048 0.002024\n",
      "Ochsner LSU Health System of North Louisiana    Baa    0.02 0.50 0.010740 0.005370\n",
      "                                   AT&T Inc.    Baa    0.02 0.65 0.010740 0.006981\n",
      "                           Bell Canada, Inc.     Ba    0.02 0.95 0.037935 0.036038\n",
      "              British Telecommunications plc    Baa    0.02 0.65 0.010740 0.006981\n",
      "                              NBN Co Limited     Aa    0.02 0.65 0.004048 0.002631\n",
      "                          Energy Transfer LP     Ba    0.08 0.95 0.037935 0.036038\n",
      "             Keenan Fort Detrick Energy, LLC     Aa    0.02 0.50 0.004048 0.002024\n",
      "                                  PacifiCorp    Baa    0.02 0.95 0.010740 0.010203\n",
      "                              TechnipFMC plc    Baa    0.03 0.65 0.010740 0.006981\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "y1 = pd.read_csv(\"ar1_forecasts_5y.csv\")\n",
    "y1 = y1[y1[\"year_ahead\"]==5].copy()   # change this accordingly == x\n",
    "\n",
    "\n",
    "\n",
    "lgd_map = {    #stressed LGD assumptions\n",
    "    \"Senior Secured\": 0.50,\n",
    "    \"Secured\": 0.50,\n",
    "    \"Senior Unsecured\": 0.65,\n",
    "    \"Senior Subordinate\": 0.75,\n",
    "    \"Subordinate\": 0.80,\n",
    "    \"Junior Subordinate\": 0.95,\n",
    "    \"All Bonds\": 0.75\n",
    "}\n",
    "\n",
    "bonds1[\"LGD\"] = bonds1[\"security_class\"].map(lgd_map)\n",
    "\n",
    "def portfolio_edl(toy_df, y1_df, scenario_col):\n",
    "    merged = toy_df.merge(y1_df[[\"rating\", scenario_col]].rename(columns={scenario_col:\"DR\"}), on=\"rating\", how=\"left\")\n",
    "    merged[\"EDL\"] = merged[\"DR\"] * merged[\"LGD\"]              \n",
    "    port_edl = (merged[\"EDL\"] * merged[\"weight\"]).sum()       \n",
    "    return port_edl, merged\n",
    "\n",
    "# Compute for each scenario\n",
    "for sc_col, label in [(\"DR_base\",\"Base\"), (\"DR_severe\",\"Severe\")]:\n",
    "    port_loss, detail = portfolio_edl(bonds1, y1, sc_col)\n",
    "    print(f\"\\nPortfolio 5-year EDL ({label}): {port_loss*100:.3f}%\")\n",
    "    print(detail[[\"id\",\"rating\",\"weight\",\"LGD\",\"DR\",\"EDL\"]].round(6).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f607306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Single-number] Year+5 portfolio PD (Base): 0.407%\n",
      "[Single-number] Year+5 portfolio EDL (Base): 0.338%\n",
      "[Parametric] Year+5 portfolio PD 95% ub: 1.653% | 99% ub: 1.659%\n",
      "[Parametric] Year+5 portfolio EDL 95% : 1.356% | 99%   : 1.359%\n"
     ]
    }
   ],
   "source": [
    "# Testing the parametric PD bounds calculation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FCAST_PATH = \"ar1_forecasts_5y.csv\"         \n",
    "PARAMS_PATH = \"ar1_params_by_rating.csv\"    \n",
    "\n",
    "\n",
    "H = 5\n",
    "SCENARIO_COL = \"DR_base\"   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = pd.read_csv(FCAST_PATH)\n",
    "drH_base = f.loc[f[\"year_ahead\"]==H, [\"rating\", SCENARIO_COL]].rename(columns={SCENARIO_COL:\"DR\"})\n",
    "m = bonds1.merge(drH_base, on=\"rating\", how=\"left\")\n",
    "portfolio_PD_base = (m[\"weight\"] * m[\"DR\"]).sum()\n",
    "portfolio_EDL_base = (m[\"weight\"] * m[\"LGD\"] * m[\"DR\"]).sum()\n",
    "\n",
    "print(f\"[Single-number] Year+{H} portfolio PD (Base): {portfolio_PD_base*100:.3f}%\")\n",
    "print(f\"[Single-number] Year+{H} portfolio EDL (Base): {portfolio_EDL_base*100:.3f}%\")\n",
    "\n",
    "\n",
    "Z95, Z99 = 1.96, 2.576\n",
    "ar = pd.read_csv(PARAMS_PATH).set_index(\"rating\")\n",
    "\n",
    "def hstep_var(phi, sigma, h):\n",
    "    # sigma = residual s.d. from AR(1) one-step; accumulate for h-steps ahead\n",
    "    if abs(phi) == 1.0:\n",
    "        return (sigma**2) * h\n",
    "    return (sigma**2) * (1 - (phi**2)**h) / (1 - phi**2)\n",
    "\n",
    "\n",
    "base_by_rating = drH_base.set_index(\"rating\")[\"DR\"].to_dict()\n",
    "\n",
    "\n",
    "bounds = {}\n",
    "for r, row in ar.iterrows():\n",
    "    if r not in base_by_rating: \n",
    "        continue\n",
    "    mu_h = float(base_by_rating[r])               # use your forecasted Base mean at H\n",
    "    var_h = hstep_var(row[\"phi\"], row[\"sigma\"], H)\n",
    "    sd_h  = float(np.sqrt(max(var_h, 0.0)))\n",
    "    ub95  = mu_h + Z95 * sd_h\n",
    "    ub99  = mu_h + Z99 * sd_h\n",
    "    # clip to [0,1] and optionally cap at historical 95th percentile\n",
    "    ub95 = max(0.0, min(ub95, 1.0, row[\"q95\"]))\n",
    "    ub99 = max(0.0, min(ub99, 1.0, row[\"q95\"]))\n",
    "    bounds[r] = dict(PD_base=mu_h, PD_ub95=ub95, PD_ub99=ub99)\n",
    "\n",
    "\n",
    "PD95 = PD99 = 0.0\n",
    "EDL95 = EDL99 = 0.0\n",
    "for _, hld in bonds1.iterrows():\n",
    "    r = hld[\"rating\"]\n",
    "    if r not in bounds: \n",
    "        continue\n",
    "    PD95 += hld[\"weight\"] * bounds[r][\"PD_ub95\"]\n",
    "    PD99 += hld[\"weight\"] * bounds[r][\"PD_ub99\"]\n",
    "    EDL95 += hld[\"weight\"] * hld[\"LGD\"] * bounds[r][\"PD_ub95\"]\n",
    "    EDL99 += hld[\"weight\"] * hld[\"LGD\"] * bounds[r][\"PD_ub99\"]\n",
    "\n",
    "print(f\"[Parametric] Year+{H} portfolio PD 95% ub: {PD95*100:.3f}% | 99% ub: {PD99*100:.3f}%\")\n",
    "print(f\"[Parametric] Year+{H} portfolio EDL 95% : {EDL95*100:.3f}% | 99%   : {EDL99*100:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe44cd2",
   "metadata": {},
   "source": [
    "###### Combining both ETFs and Bonds to construct entire portfolio for calculations (Personal workings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04fded6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year+5 portfolio PD (DR_base): 0.505%\n",
      "Year+5 portfolio EDL (DR_base): 0.410%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Combine bonds + ETF slices\n",
    "portfolio = pd.concat([bonds1, etf_df], ignore_index=True)\n",
    "\n",
    "# 2) Choose horizon and scenario column\n",
    "h = 5                          # e.g., 5-year forecast\n",
    "scenario = \"DR_base\"           # or DR_mild / DR_severe\n",
    "\n",
    "# 3) Pull the rating forecast for that horizon\n",
    "dr_h = (forecast[forecast[\"year_ahead\"] == h]\n",
    "        .loc[:, [\"rating\", scenario]]\n",
    "        .rename(columns={scenario: \"DR\"}))\n",
    "\n",
    "# 4) Merge DR onto portfolio lines\n",
    "port_h = portfolio.merge(dr_h, on=\"rating\", how=\"left\")\n",
    "\n",
    "# 5) Map LGD (you can plug your recovery-based LGDs here)\n",
    "\n",
    "lgd_map = {    #stressed LGD assumptions\n",
    "    \"Senior Secured\": 0.50,\n",
    "    \"Secured\": 0.50,\n",
    "    \"Senior Unsecured\": 0.65,\n",
    "    \"Senior Subordinate\": 0.75,\n",
    "    \"Subordinate\": 0.80,\n",
    "    \"Junior Subordinate\": 0.95,\n",
    "    \"All Bonds\": 0.75\n",
    "}\n",
    "\n",
    "port_h[\"LGD\"] = port_h[\"security_class\"].map(lgd_map)\n",
    "\n",
    "# 6) Compute portfolio PD and EDL for the horizon\n",
    "port_h[\"EDL\"] = port_h[\"weight\"] * port_h[\"DR\"] * port_h[\"LGD\"]\n",
    "port_pd  = (port_h[\"weight\"] * port_h[\"DR\"]).sum()\n",
    "port_edl = port_h[\"EDL\"].sum()\n",
    "\n",
    "print(f\"Year+{h} portfolio PD ({scenario}): {100*port_pd:.3f}%\")\n",
    "print(f\"Year+{h} portfolio EDL ({scenario}): {100*port_edl:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea27b75",
   "metadata": {},
   "source": [
    "###### Personal workings for the cell below, not final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "048d0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Full] Year+10 portfolio PD (Base): 2.006%\n",
      "[Full] Year+10 portfolio EDL (Base): 1.611%\n",
      "[Full Parametric] Year+10 portfolio PD 95% ub: 2.015% | 99% ub: 2.015%\n",
      "[Full Parametric] Year+10 portfolio EDL 95% : 1.617% | 99%   : 1.617%\n"
     ]
    }
   ],
   "source": [
    "FCAST_PATH  = \"ar1_forecasts_5y.csv\"\n",
    "PARAMS_PATH = \"ar1_params_by_rating.csv\"\n",
    "H            = 10\n",
    "SCENARIO_COL = \"DR_severe\" \n",
    "\n",
    "# ---- Load AR(1) forecast and params ----\n",
    "f  = pd.read_csv(FCAST_PATH)\n",
    "ar = pd.read_csv(PARAMS_PATH).set_index(\"rating\")\n",
    "\n",
    "# horizon DR by rating (chosen scenario)\n",
    "drH = (f.loc[f[\"year_ahead\"]==H, [\"rating\", SCENARIO_COL]]\n",
    "         .rename(columns={SCENARIO_COL:\"DR\"}))\n",
    "\n",
    "# Merge DR to each line\n",
    "fullH = portfolio.merge(drH, on=\"rating\", how=\"left\")\n",
    "\n",
    "lgd_map = {    #stressed LGD assumptions\n",
    "    \"Senior Secured\": 0.50,\n",
    "    \"Secured\": 0.50,\n",
    "    \"Senior Unsecured\": 0.65,\n",
    "    \"Senior Subordinate\": 0.75,\n",
    "    \"Subordinate\": 0.80,\n",
    "    \"Junior Subordinate\": 0.95,\n",
    "    \"All Bonds\": 0.75\n",
    "}\n",
    "\n",
    "fullH[\"LGD\"] = fullH[\"security_class\"].map(lgd_map)\n",
    "\n",
    "# Single-number PD/EDL\n",
    "PD_base  = (fullH[\"weight\"] * fullH[\"DR\"]).sum()\n",
    "EDL_base = (fullH[\"weight\"] * fullH[\"DR\"] * fullH[\"LGD\"]).sum()\n",
    "print(f\"[Full] Year+{H} portfolio PD (Base): {PD_base*100:.3f}%\")\n",
    "print(f\"[Full] Year+{H} portfolio EDL (Base): {EDL_base*100:.3f}%\")\n",
    "\n",
    "# ---- Parametric bounds using AR(1) variance build-up ----\n",
    "Z95, Z99 = 1.96, 2.576\n",
    "\n",
    "def hstep_var(phi, sigma, h):\n",
    "    # AR(1) h-step variance of the *innovation* sum; sigma is 1-step resid s.d.\n",
    "    if abs(phi) == 1.0:\n",
    "        return (sigma**2) * h\n",
    "    return (sigma**2) * (1 - (phi**2)**h) / (1 - phi**2)\n",
    "\n",
    "# Prepare per-rating base mean\n",
    "base_by_rating = drH.set_index(\"rating\")[\"DR\"].to_dict()\n",
    "\n",
    "# Compute per-rating upper bounds\n",
    "bounds = {}\n",
    "for r, row in ar.iterrows():\n",
    "    if r not in base_by_rating:\n",
    "        continue\n",
    "    mu_h = float(base_by_rating[r])\n",
    "    var_h = hstep_var(row[\"phi\"], row[\"sigma\"], H)\n",
    "    sd_h  = float(np.sqrt(max(var_h, 0.0)))\n",
    "    ub95  = max(0.0, min(mu_h + Z95*sd_h, 1.0, row[\"q95\"]))\n",
    "    ub99  = max(0.0, min(mu_h + Z99*sd_h, 1.0, row[\"q95\"]))\n",
    "    bounds[r] = {\"PD_base\":mu_h, \"PD_ub95\":ub95, \"PD_ub99\":ub99}\n",
    "\n",
    "# Aggregate to portfolio\n",
    "PD95 = PD99 = 0.0\n",
    "EDL95 = EDL99 = 0.0\n",
    "for _, hld in fullH.iterrows():\n",
    "    r = hld[\"rating\"]\n",
    "    if r not in bounds:\n",
    "        continue\n",
    "    PD95 += hld[\"weight\"] * bounds[r][\"PD_ub95\"]\n",
    "    PD99 += hld[\"weight\"] * bounds[r][\"PD_ub99\"]\n",
    "    EDL95 += hld[\"weight\"] * hld[\"LGD\"] * bounds[r][\"PD_ub95\"]\n",
    "    EDL99 += hld[\"weight\"] * hld[\"LGD\"] * bounds[r][\"PD_ub99\"]\n",
    "\n",
    "print(f\"[Full Parametric] Year+{H} portfolio PD 95% ub: {PD95*100:.3f}% | 99% ub: {PD99*100:.3f}%\")\n",
    "print(f\"[Full Parametric] Year+{H} portfolio EDL 95% : {EDL95*100:.3f}% | 99%   : {EDL99*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262f53a",
   "metadata": {},
   "source": [
    "### Run the cell below for different scenarios, as this is more complete and slightly more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Full] Year+5 portfolio PD (Severe): 2.006%\n",
      "[Full] Year+5 portfolio EDL (Severe): 1.611%\n",
      "[Full Parametric] Year+5 portfolio PD 95% ub: 2.015% | 99% ub: 2.015%\n",
      "[Full Parametric] Year+5 portfolio EDL 95% : 1.617% | 99%   : 1.617%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FCAST_PATH  = \"ar1_forecasts_5y.csv\"     \n",
    "PARAMS_PATH = \"ar1_params_by_rating.csv\" \n",
    "\n",
    "H            = 5            \n",
    "SCENARIO_COL = \"DR_severe\"      \n",
    "\n",
    "\n",
    "f  = pd.read_csv(FCAST_PATH)\n",
    "ar = pd.read_csv(PARAMS_PATH).set_index(\"rating\")\n",
    "\n",
    "# sanity: make sure the forecast actually has this horizon & scenario\n",
    "if SCENARIO_COL not in f.columns:\n",
    "    raise ValueError(f\"{SCENARIO_COL} not found in {FCAST_PATH} columns: {list(f.columns)}\")\n",
    "if H not in set(f[\"year_ahead\"].unique()):\n",
    "    raise ValueError(f\"H={H} not found in 'year_ahead' of {FCAST_PATH}. \"\n",
    "                     f\"Available: {sorted(f['year_ahead'].unique())}\")\n",
    "\n",
    "\n",
    "drH = (f.loc[f[\"year_ahead\"] == H, [\"rating\", SCENARIO_COL]]\n",
    "         .rename(columns={SCENARIO_COL: \"DR\"}))\n",
    "\n",
    "\n",
    "fullH = portfolio.merge(drH, on=\"rating\", how=\"left\")\n",
    "\n",
    "\n",
    "lgd_map = {\n",
    "    \"Senior Secured\":      0.50,\n",
    "    \"Secured\":             0.50,\n",
    "    \"Senior Unsecured\":    0.65,\n",
    "    \"Senior Subordinate\":  0.75,\n",
    "    \"Subordinate\":         0.80,\n",
    "    \"Junior Subordinate\":  0.95,\n",
    "    \"All Bonds\":           0.75,\n",
    "}\n",
    "fullH[\"LGD\"] = fullH[\"security_class\"].map(lgd_map).fillna(0.65)  \n",
    "\n",
    "\n",
    "PD_scn  = (fullH[\"weight\"] * fullH[\"DR\"]).sum()\n",
    "EDL_scn = (fullH[\"weight\"] * fullH[\"DR\"] * fullH[\"LGD\"]).sum()\n",
    "print(f\"[Full] Year+{H} portfolio PD ({SCENARIO_COL.split('_')[1].title()}): {PD_scn*100:.3f}%\")\n",
    "print(f\"[Full] Year+{H} portfolio EDL ({SCENARIO_COL.split('_')[1].title()}): {EDL_scn*100:.3f}%\")\n",
    "\n",
    "Z95, Z99 = 1.96, 2.576\n",
    "\n",
    "def hstep_sd(phi, sigma, h):\n",
    "   \n",
    "    phi = float(phi)\n",
    "    sigma = float(sigma)\n",
    "    if abs(phi) < 0.15:\n",
    "        return sigma * np.sqrt(h)              \n",
    "    \n",
    "    var_h = (sigma**2) * (1 - (phi**2)**h) / (1 - phi**2)\n",
    "    return float(np.sqrt(max(var_h, 0.0)))\n",
    "\n",
    "# per-rating base mean at H\n",
    "base_by_rating = drH.set_index(\"rating\")[\"DR\"].to_dict()\n",
    "\n",
    "# compute per-rating UB95 / UB99\n",
    "bounds = {}\n",
    "for r, row in ar.iterrows():\n",
    "    if r not in base_by_rating: \n",
    "        continue\n",
    "    mu_h = float(base_by_rating[r])\n",
    "    sd_h = hstep_sd(row[\"phi\"], row[\"sigma\"], H)\n",
    "    ub95 = mu_h + Z95 * sd_h\n",
    "    ub99 = mu_h + Z99 * sd_h\n",
    "    \n",
    "    q95  = float(row.get(\"q95\", 1.0))\n",
    "    ub95 = max(0.0, min(ub95, 1.0, q95))\n",
    "    ub99 = max(0.0, min(ub99, 1.0, q95))\n",
    "    bounds[r] = {\"PD_base\": mu_h, \"PD_ub95\": ub95, \"PD_ub99\": ub99}\n",
    "\n",
    "# aggregate portfolio UB95 / UB99\n",
    "PD95 = PD99 = 0.0\n",
    "EDL95 = EDL99 = 0.0\n",
    "for _, hld in fullH.iterrows():\n",
    "    r = hld[\"rating\"]\n",
    "    if r not in bounds: \n",
    "        continue\n",
    "    PD95  += hld[\"weight\"] * bounds[r][\"PD_ub95\"]\n",
    "    PD99  += hld[\"weight\"] * bounds[r][\"PD_ub99\"]\n",
    "    EDL95 += hld[\"weight\"] * hld[\"LGD\"] * bounds[r][\"PD_ub95\"]\n",
    "    EDL99 += hld[\"weight\"] * hld[\"LGD\"] * bounds[r][\"PD_ub99\"]\n",
    "\n",
    "print(f\"[Full Parametric] Year+{H} portfolio PD 95% ub: {PD95*100:.3f}% | 99% ub: {PD99*100:.3f}%\")\n",
    "print(f\"[Full Parametric] Year+{H} portfolio EDL 95% : {EDL95*100:.3f}% | 99%   : {EDL99*100:.3f}%\")\n",
    "\n",
    "# # (optional) quick debug view of per-rating DR at H\n",
    "# dbg = fullH[[\"id\",\"rating\",\"weight\",\"security_class\",\"LGD\",\"DR\"]].sort_values(\"rating\")\n",
    "# # print(dbg.to_string(index=False))  # uncomment if you want to inspect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926a68b",
   "metadata": {},
   "source": [
    "### Finalized dataframe from running the models at different horizons and different severity scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "43abfc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Stress Test Summary Table:\n",
      " Horizon (yrs) Scenario PD (Base) EDL (Base) PD 95% UB PD 99% UB EDL 95% UB EDL 99% UB\n",
      "             5     Base    0.505%      0.41%    2.004%    2.015%      1.61%     1.617%\n",
      "             7     Base    0.509%     0.412%    2.004%    2.015%      1.61%     1.617%\n",
      "            10     Base     0.51%     0.413%    2.004%    2.015%      1.61%     1.617%\n",
      "             5   Severe    2.006%     1.611%    2.015%    2.015%     1.617%     1.617%\n",
      "             7   Severe    2.006%     1.611%    2.015%    2.015%     1.617%     1.617%\n",
      "            10   Severe    2.006%     1.611%    2.015%    2.015%     1.617%     1.617%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Construct your summary table ---\n",
    "data = [\n",
    "    [5,  \"Base\",   0.00505, 0.00410, 0.02004, 0.02015, 0.01610, 0.01617],\n",
    "    [7,  \"Base\",   0.00509, 0.00412, 0.02004, 0.02015, 0.01610, 0.01617],\n",
    "    [10, \"Base\",   0.00510, 0.00413, 0.02004, 0.02015, 0.01610, 0.01617],\n",
    "    [5,  \"Severe\", 0.02006, 0.01611, 0.02015, 0.02015, 0.01617, 0.01617],\n",
    "    [7,  \"Severe\", 0.02006, 0.01611, 0.02015, 0.02015, 0.01617, 0.01617],\n",
    "    [10, \"Severe\", 0.02006, 0.01611, 0.02015, 0.02015, 0.01617, 0.01617],\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    \"Horizon (yrs)\", \"Scenario\",\n",
    "    \"PD (Base)\", \"EDL (Base)\",\n",
    "    \"PD 95% UB\", \"PD 99% UB\",\n",
    "    \"EDL 95% UB\", \"EDL 99% UB\"\n",
    "]\n",
    "\n",
    "results_table = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "# Format neatly as percentages with 3 decimals\n",
    "formatted_table = results_table.copy()\n",
    "for c in cols[2:]:\n",
    "    formatted_table[c] = (results_table[c] * 100).round(3).astype(str) + \"%\"\n",
    "\n",
    "print(\"Portfolio Stress Test Summary Table:\")\n",
    "print(formatted_table.to_string(index=False))\n",
    "\n",
    "# # Optional: save as CSV for reporting\n",
    "# formatted_table.to_csv(\"portfolio_stress_summary.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
